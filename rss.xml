<?xml version="1.0" encoding="UTF-8"?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>Engineering Digest</title>
    <link>https://github.com/yourusername/eng-digest</link>
    <description>Daily digest of engineering blog posts from top tech companies</description>
    <language>en-us</language>
    <atom:link href="https://github.com/yourusername/eng-digest/rss.xml" rel="self" type="application/rss+xml"/>
    <lastBuildDate>Thu, 19 Feb 2026 09:42:40 GMT</lastBuildDate>
    <generator>Eng Digest</generator>
    <item>
      <title>Pick up exactly where you left off with Session Management in Gemini CLI</title>
      <link>https://developers.googleblog.com/pick-up-exactly-where-you-left-off-with-session-management-in-gemini-cli/</link>
      <description>Gemini CLI&amp;apos;s new automatic **Session Management** (v0.20.0+) saves your conversation history, tool outputs, and reasoning, providing project-specific context This feature ensures you never lose your work state, capturing prompts, tool execution details, and usage stats Customize history with cleanup policies in `settings.json`.</description>
      <pubDate>Thu, 19 Feb 2026 09:42:37 GMT</pubDate>
      <guid isPermaLink="true">https://developers.googleblog.com/pick-up-exactly-where-you-left-off-with-session-management-in-gemini-cli/</guid>
      <source>Google Developers</source>
    </item>
    <item>
      <title>Building agents with the ADK and the new Interactions API</title>
      <link>https://developers.googleblog.com/building-agents-with-the-adk-and-the-new-interactions-api/</link>
      <description>The new Gemini Interactions API enables stateful, multi-turn AI agent workflows, providing a single interface for raw models and the Gemini Deep Research Agent It can be integrated with existing ADK systems as a superior inference engine with simplified state management, or used as a transparent remote A2A agent via InteractionsApiTransport, allowing seamless expansion of multi-agent systems with minimal refactoring.</description>
      <pubDate>Thu, 19 Feb 2026 09:42:37 GMT</pubDate>
      <guid isPermaLink="true">https://developers.googleblog.com/building-agents-with-the-adk-and-the-new-interactions-api/</guid>
      <source>Google Developers</source>
    </item>
    <item>
      <title>Introducing A2UI: An open project for agent-driven interfaces</title>
      <link>https://developers.googleblog.com/introducing-a2ui-an-open-project-for-agent-driven-interfaces/</link>
      <description>A2UI is an open-source project for agent-driven, cross-platform, and generative UI It provides a secure, declarative data format for agents to compose bespoke interfaces from a trusted component catalog, allowing for native styling and incremental updates Designed for the multi-agent mesh (A2A), it offers a framework-agnostic solution to safely render remote agent UIs, with integrations in AG UI, Flutter&amp;apos;s GenUI SDK, Opal, and Gemini Enterprise.</description>
      <pubDate>Thu, 19 Feb 2026 09:42:37 GMT</pubDate>
      <guid isPermaLink="true">https://developers.googleblog.com/introducing-a2ui-an-open-project-for-agent-driven-interfaces/</guid>
      <source>Google Developers</source>
    </item>
    <item>
      <title>What to expect for open source in 2026</title>
      <link>https://github.blog/open-source/maintainers/what-to-expect-for-open-source-in-2026/</link>
      <description>Let’s dig into the 2025’s open source data on GitHub to see what we can learn about the future The post What to expect for open source in 2026 appeared first on The GitHub Blog.</description>
      <pubDate>Wed, 18 Feb 2026 18:41:42 GMT</pubDate>
      <guid isPermaLink="true">https://github.blog/open-source/maintainers/what-to-expect-for-open-source-in-2026/</guid>
      <source>GitHub Blog</source>
    </item>
    <item>
      <title>Securing the AI software supply chain: Security results across 67 open source projects</title>
      <link>https://github.blog/open-source/maintainers/securing-the-ai-software-supply-chain-security-results-across-67-open-source-projects/</link>
      <description>Learn how The GitHub Secure Open Source Fund helped 67 critical AI‑stack projects accelerate fixes, strengthen ecosystems, and advance open source resilience The post Securing the AI software supply chain: Security results across 67 open source projects appeared first on The GitHub Blog.</description>
      <pubDate>Tue, 17 Feb 2026 19:00:00 GMT</pubDate>
      <guid isPermaLink="true">https://github.blog/open-source/maintainers/securing-the-ai-software-supply-chain-security-results-across-67-open-source-projects/</guid>
      <source>GitHub Blog</source>
    </item>
    <item>
      <title>Amazon EC2 Hpc8a Instances powered by 5th Gen AMD EPYC processors are now available</title>
      <link>https://aws.amazon.com/blogs/aws/amazon-ec2-hpc8a-instances-powered-by-5th-gen-amd-epyc-processors-are-now-available/</link>
      <description>Amazon EC2 Hpc8a instances, powered by 5th Gen AMD EPYC processors, deliver up to 40% higher performance, increased memory bandwidth, and 300 Gbps Elastic Fabric Adapter networking, helping customers accelerate compute-intensive simulations, engineering workloads, and tightly coupled HPC applications.</description>
      <pubDate>Mon, 16 Feb 2026 23:12:37 GMT</pubDate>
      <guid isPermaLink="true">https://aws.amazon.com/blogs/aws/amazon-ec2-hpc8a-instances-powered-by-5th-gen-amd-epyc-processors-are-now-available/</guid>
      <source>AWS News</source>
    </item>
    <item>
      <title>Announcing Amazon SageMaker Inference for custom Amazon Nova models</title>
      <link>https://aws.amazon.com/blogs/aws/announcing-amazon-sagemaker-inference-for-custom-amazon-nova-models/</link>
      <description>AWS launches Amazon SageMaker Inference for custom Amazon Nova models You can now configure the instance types, auto-scaling policies, and concurrency settings for custom Nova model deployments to best meet their needs.</description>
      <pubDate>Mon, 16 Feb 2026 21:25:23 GMT</pubDate>
      <guid isPermaLink="true">https://aws.amazon.com/blogs/aws/announcing-amazon-sagemaker-inference-for-custom-amazon-nova-models/</guid>
      <source>AWS News</source>
    </item>
    <item>
      <title>AWS Weekly Roundup: Amazon EC2 M8azn instances, new open weights models in Amazon Bedrock, and more (February 16, 2026)</title>
      <link>https://aws.amazon.com/blogs/aws/aws-weekly-roundup-amazon-ec2-m8azn-instances-new-open-weights-models-in-amazon-bedrock-and-more-february-16-2026/</link>
      <description>I joined AWS in 2021, and since then I’ve watched the Amazon Elastic Compute Cloud (Amazon EC2) instance family grow at a pace that still surprises me From AWS Graviton-powered instances to specialized accelerated computing options, it feels like every few months there’s a new instance type landing that pushes performance boundaries further</description>
      <pubDate>Mon, 16 Feb 2026 17:28:52 GMT</pubDate>
      <guid isPermaLink="true">https://aws.amazon.com/blogs/aws/aws-weekly-roundup-amazon-ec2-m8azn-instances-new-open-weights-models-in-amazon-bedrock-and-more-february-16-2026/</guid>
      <source>AWS News</source>
    </item>
    <item>
      <title>Automate repository tasks with GitHub Agentic Workflows</title>
      <link>https://github.blog/ai-and-ml/automate-repository-tasks-with-github-agentic-workflows/</link>
      <description>Discover GitHub Agentic Workflows, now in technical preview Build automations using coding agents in GitHub Actions to handle triage, documentation, code quality, and more The post Automate repository tasks with GitHub Agentic Workflows appeared first on The GitHub Blog.</description>
      <pubDate>Fri, 13 Feb 2026 14:00:00 GMT</pubDate>
      <guid isPermaLink="true">https://github.blog/ai-and-ml/automate-repository-tasks-with-github-agentic-workflows/</guid>
      <source>GitHub Blog</source>
    </item>
    <item>
      <title>Scaling LLM Post-Training at Netflix</title>
      <link>https://netflixtechblog.com/scaling-llm-post-training-at-netflix-0046f8790194?source=rss----2615bd06b42e---4</link>
      <description>This blog describes the architecture and engineering philosophy of our internal Post-Training Framework, built by the AI Platform team to hide infrastructure complexity so researchers and model developers can focus on model innovation — not distributed systems plumbing.A Model Developer’s Post-Training JourneyPost-training often starts deceptively simply: curate proprietary domain data, load an open-weight model from Hugging Face, and iterate batches through it In particular, we extend Single Program, Multiple Data (SPMD) style SFT workloads to run online RL with a hybrid single-controller + SPMD execution model, which we’ll describe next.Today, this framework supports research use cases ranging from post-training large-scale foundation models to fine-tuning specialized expert models Rather than training directly on transformers model classes, we maintain our own optimized, unified model definitions that can still load/save Hugging Face checkpoints</description>
      <pubDate>Fri, 13 Feb 2026 08:05:33 GMT</pubDate>
      <guid isPermaLink="true">https://netflixtechblog.com/scaling-llm-post-training-at-netflix-0046f8790194?source=rss----2615bd06b42e---4</guid>
      <source>Netflix TechBlog</source>
    </item>
    <item>
      <title>How low-bit inference enables efficient AI</title>
      <link>https://dropbox.tech/machine-learning/how-low-bit-inference-enables-efficient-ai</link>
      <description>Making products like Dropbox Dash accessible to individuals and businesses means tackling new challenges around efficiency and resource use.</description>
      <pubDate>Thu, 12 Feb 2026 18:00:00 GMT</pubDate>
      <guid isPermaLink="true">https://dropbox.tech/machine-learning/how-low-bit-inference-enables-efficient-ai</guid>
      <source>Dropbox Engineering</source>
    </item>
    <item>
      <title>Automating RDS Postgres to Aurora Postgres Migration</title>
      <link>https://netflixtechblog.com/automating-rds-postgres-to-aurora-postgres-migration-261ca045447f?source=rss----2615bd06b42e---4</link>
      <description>At this stage, the Aurora cluster is created and attached to the RDS PostgreSQL primary as a replica, establishing continuous replication from the source RDS PostgreSQL instance The cluster is fully operational for validation and performance testing, but it is not yet writable — RDS remains the authoritative primary.Quiescence PhaseThe goal of the quiescence phase is to transition client applications from the source RDS PostgreSQL instance to the Aurora PostgreSQL cluster as the new primary database, while preserving data consistency during cutover.The first step in this process is to stop all write traffic to the source RDS PostgreSQL instance to guarantee consistency In addition, any logical replication slots removed during the migration must be recreated so that CDC consumers can continue processing changes from the source database.Once connectivity and replication slots are restored, the RDS PostgreSQL instance can safely resume its role as the primary source of truth.Post-quiescence Rolling back after cutover, once the Aurora PostgreSQL cluster is serving production traffic, is significantly more complex</description>
      <pubDate>Thu, 12 Feb 2026 14:07:19 GMT</pubDate>
      <guid isPermaLink="true">https://netflixtechblog.com/automating-rds-postgres-to-aurora-postgres-migration-261ca045447f?source=rss----2615bd06b42e---4</guid>
      <source>Netflix TechBlog</source>
    </item>
    <item>
      <title>The Death of Traditional Testing: Agentic Development Broke a 50-Year-Old Field, JiTTesting Can Revive It</title>
      <link>https://engineering.fb.com/2026/02/11/developer-tools/the-death-of-traditional-testing-agentic-development-jit-testing-revival/</link>
      <description>WHAT IT IS The rise of agentic software development means code is being written, reviewed, and shipped faster than ever before across the entire industry Faster development demands faster testing that can catch bugs as they land in a codebase, without [...] Read More The post The Death of Traditional Testing: Agentic Development Broke a 50-Year-Old Field, JiTTesting Can Revive It appeared first on Engineering at Meta.</description>
      <pubDate>Wed, 11 Feb 2026 17:00:05 GMT</pubDate>
      <guid isPermaLink="true">https://engineering.fb.com/2026/02/11/developer-tools/the-death-of-traditional-testing-agentic-development-jit-testing-revival/</guid>
      <source>Meta Engineering</source>
    </item>
    <item>
      <title>Insights from our executive roundtable on AI and engineering productivity</title>
      <link>https://dropbox.tech/culture/insights-from-our-executive-roundtable-on-ai-and-engineering-productivity</link>
      <description>From Claude Code to Cursor, we&amp;apos;re big adopters of AI coding tools at Dropbox The early results have been promising, but there are still a lot of open questions about how to work with these tools most effectively and where they can have the most impact To push this conversation forward, we hosted an executive roundtable at our San Francisco studio</description>
      <pubDate>Wed, 11 Feb 2026 17:00:00 GMT</pubDate>
      <guid isPermaLink="true">https://dropbox.tech/culture/insights-from-our-executive-roundtable-on-ai-and-engineering-productivity</guid>
      <source>Dropbox Engineering</source>
    </item>
    <item>
      <title>Building Prometheus: How Backend Aggregation Enables Gigawatt-Scale AI Clusters</title>
      <link>https://engineering.fb.com/2026/02/09/data-center-engineering/building-prometheus-how-backend-aggregation-enables-gigawatt-scale-ai-clusters/</link>
      <description>We’re sharing details of the role backend aggregation (BAG) plays in building Meta’s gigawatt-scale AI clusters like Prometheus Once it’s complete our AI [...] Read More The post Building Prometheus: How Backend Aggregation Enables Gigawatt-Scale AI Clusters appeared first on Engineering at Meta.</description>
      <pubDate>Mon, 09 Feb 2026 17:00:33 GMT</pubDate>
      <guid isPermaLink="true">https://engineering.fb.com/2026/02/09/data-center-engineering/building-prometheus-how-backend-aggregation-enables-gigawatt-scale-ai-clusters/</guid>
      <source>Meta Engineering</source>
    </item>
    <item>
      <title>No Display? No Problem: Cross-Device Passkey Authentication for XR Devices</title>
      <link>https://engineering.fb.com/2026/02/04/security/cross-device-passkey-authentication-for-xr-devices-meta-quest/</link>
      <description>We’re sharing a novel approach to enabling cross-device passkey authentication for devices with inaccessible displays (like XR devices) Our approach bypasses the use of QR codes and enables cross-device authentication without the need for an on-device display, while still complying with all trust and proximity requirements No Problem: Cross-Device Passkey Authentication for XR Devices appeared first on Engineering at Meta.</description>
      <pubDate>Wed, 04 Feb 2026 22:00:07 GMT</pubDate>
      <guid isPermaLink="true">https://engineering.fb.com/2026/02/04/security/cross-device-passkey-authentication-for-xr-devices-meta-quest/</guid>
      <source>Meta Engineering</source>
    </item>
    <item>
      <title>Engineering VP Josh Clemm on how we use knowledge graphs, MCP, and DSPy in Dash</title>
      <link>https://dropbox.tech/machine-learning/vp-josh-clemm-knowledge-graphs-mcp-and-dspy-dash</link>
      <description>Engineering VP Josh Clemm deep-dives into how we think about knowledge graphs, indexes, MCP, and prompt optimization using tools like DSPy.</description>
      <pubDate>Wed, 28 Jan 2026 18:00:00 GMT</pubDate>
      <guid isPermaLink="true">https://dropbox.tech/machine-learning/vp-josh-clemm-knowledge-graphs-mcp-and-dspy-dash</guid>
      <source>Dropbox Engineering</source>
    </item>
    <item>
      <title>The AI Evolution of Graph Search at Netflix</title>
      <link>https://netflixtechblog.com/the-ai-evolution-of-graph-search-at-netflix-d416ec5b1151?source=rss----2615bd06b42e---4</link>
      <description>We need the LLM to generate a Graph Search Filter DSL statement that is syntactically, semantically, and pragmatically correct.Syntactic correctness is easy — does it parse For some fields, there is additional information we can provide beyond what’s available in the schema as well, in particular permissible values that pull from controlled vocabularies.Each field in the index is associated with metadata as seen below, and that metadata is provided as part of the context.Graph Search index representationThe field is derived from the document path as characterized by the GraphQL query.The description is the comment from the GraphQL schema for the field.The type is derived from the GraphQL schema for the field e.g This design strategically balances LLM involvement with more deterministic strategies.End-to-end architectureThe end-to-end process is as follows:A user’s natural language question (with optional `@mentions` statements) are provided as input, along with the Graph Search index contextThe context is scoped by using the RAG pattern on both fields and possible valuesThe pre-processed context and the question are fed into the LLM with an instruction asking for a syntactically and semantically correct filter statementThe generated filer statement DSL is verified and checked for hallucinationsThe final response contains the related AST in order to build “Chips” and “Facets”SummaryBy combining our existing Graph Search infrastructure with the power and flexibility of LLMs, we’ve bridged the gap between complex filter statements and user intent</description>
      <pubDate>Mon, 26 Jan 2026 19:01:27 GMT</pubDate>
      <guid isPermaLink="true">https://netflixtechblog.com/the-ai-evolution-of-graph-search-at-netflix-d416ec5b1151?source=rss----2615bd06b42e---4</guid>
      <source>Netflix TechBlog</source>
    </item>
    <item>
      <title>Metronome + Stripe: Building the future of billing</title>
      <link>https://stripe.com/blog/metronome-stripe-building-the-future-of-billing</link>
      <description>Together, Metronome and Stripe are building the most flexible and complete billing solution on the market—one that works for everyone, from engineers in a garage figuring out their business model to public companies monetizing at global scale.</description>
      <pubDate>Fri, 23 Jan 2026 00:00:00 GMT</pubDate>
      <guid isPermaLink="true">https://stripe.com/blog/metronome-stripe-building-the-future-of-billing</guid>
      <source>Stripe Engineering</source>
    </item>
  </channel>
</rss>
